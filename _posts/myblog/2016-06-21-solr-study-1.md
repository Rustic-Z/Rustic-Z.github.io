---
title: Apach Solr搜索服务器搭建
tagline: ""
last_updated: ""
category : solr
layout: post
tags : [solr]
published: true
description: ""
---
{% include JB/setup %}

solr版本：4.4.0  
下载地址:[http://archive.apache.org/dist/lucene/solr/](http://archive.apache.org/dist/lucene/solr/)  
tomcat版本：6.x  
jdk版本：1.6.0_45  

# 在同一个tomcat下配置第二个webapp  

1、修改tomcatol/conf/service.xml:  

```
<Service name="webapp-solr">
  <Connector port="8180" protocol="HTTP/1.1"
           connectionTimeout="20000"
           redirectPort="8443"
           URIEncoding="UTF-8" />
  <Connector port="8019" protocol="AJP/1.3" redirectPort="8443" />
  <Engine name="webapp-solr" defaultHost="localhost">
    <Realm className="org.apache.catalina.realm.UserDatabaseRealm"
           resourceName="UserDatabase"/>
    <Host name="localhost"  appBase="webapp-solr"
          unpackWARs="true" autoDeploy="true"
          xmlValidation="false" xmlNamespaceAware="false">
    </Host>
  </Engine>
</Service>
```  

2、在tomcat目录下增加webapp-solr文件夹与webapps并列用于新应用的部署目录；  

3、将webapps下的文件复制到webapp-solr目录下。复制命令格式：`cp -avx /home/* /mnt/newhome`；  

4、创建配置文件目录和配置文件:  

```
../tomcatol/conf/webapp-solr/localhost/
host-manager.xml
manager.xml
```  

可参考`../tomcatol/conf/Catalina/localhost/`目录结构及文件。  

此时，可以通过在webapp-solr下部署新项目，并通过不同端口访问了。  

# solr安装部署  

1、将solr.war复制到webapp-solr下，启动tomcat，solr.war被tomcat解压出solr文件夹后，关闭tomcat，再将solr.war删除。  

```
cp /root/solr_Install/solr-4.4.0/example/webapps/solr.war /usr/local/tomcatol/webapp-solr/
```  

2、将solr-4.4.0/example/lib/ext/下的jar包复制搭配/tomcatol/webapp-solr/solr/WEB-INF/lib/下。  

```
cp -avx /root/solr_Install/solr-4.4.0/example/lib/ext/* /usr/local/tomcatol/webapp-solr/solr/WEB-INF/lib/
```  

3、将solr-4.4.0/example/resourese/log4j.properties 复制到/tomcatol/webapp-solr/solr/WEB-INF/classes/下。  

```
cp /root/solr_Install/solr-4.4.0/example/resources/log4j.properties /usr/local/tomcatol/webapp-solr/solr/WEB-INF/classes/
```  

4、在tomcat目录下新建solrhome目录用于放置solr服务器的索引库(也可自行决定放至服务器的任意目录下，下面的配置文件只要制定该目录即可)，然后将solr-4.4.0/example/solr/下的文件全都复制到solrhome/下。  

```
cp -avx /root/solr_Install/solr-4.4.0/example/solr/* /usr/local/tomcatol/solrhome/
```  

5、最后添加solr项目的配置文件，在tomcat/conf/webapp-solr/localhost/下新建solr.xml文件，内容如下：  

```
   <?xml version="1.0" encoding="utf-8"?>
   <Context path="/usr/local/tomcatol/webapp-solr/solr" docBase="/usr/local/tomcatol/webapp-solr/solr.war" debug="0" crossContext="true">
   <Environment name="solr/home" type="java.lang.String" value="/usr/local/tomcatol/solrhome/" override="false"/>
      <!-- 这边需要注意，override需要设置为false，否则每次启动tomcat都会重新解压war文件覆盖掉之前的配置，或者手动解压后，把context path直接指向文件夹 -->
   </Context>
```  

此时启动tomcat，输入121.40.131.30:8180/solr 即可看到solr项目主页。  

# 创建多索引库  

一般针对不同的业务搜索的话都会创建多索引库以免solr构建的索引混乱，也便于我们整理。以上方法部署的solr有一个默认的索引库collection1,我们可以删除它，也可以给它重配置成我们需要的索引库。  

下面我们来创建我们自己的索引库，以活动(ps_activity)为例。至于索引库的存储位置就是我们之前在tomcat根目录下创建的solrhome。  

1、solr-4.4.0/example/multicore/下有core1、core2两个索引库配置的例子，这里我们将某一个复制到我们的solrhome目录下，并创建一个core_activity目录。  

```
cp -avx /root/solr_Install/solr-4.4.0/example/multicore/core1/* /usr/local/tomcatol/solrhome/core_activity/
```  

2、接着就是修改配置文件了，将修改solrhome目录下的solr.xml文件内容如下:  

```
<solr persistent="false">

  <!--
         adminPath: RequestHandler path to manage cores.  
   If 'null' (or absent), cores will not be manageable via request handler
  -->
  <cores adminPath="/admin/cores" host="${host:}" hostPort="${port:8180}" defaultCoreName="core_activity"  hostContext="${hostContext:solr}">
    <core name="core_activity" instanceDir="core_activity" />
    <!-- <core name="core1" instanceDir="core1" /> -->
  </cores>

  <shardHandlerFactory name="shardHandlerFactory"
    class="HttpShardHandlerFactory">
    <int name="socketTimeout">${socketTimeout:0}</int>
    <int name="connTimeout">${connTimeout:0}</int>
  </shardHandlerFactory>

</solr>
```  

name是核心的名字，instanceDir是核心的路径，默认是当前目录，这个最好保持一致。  
AdminPath是指url路径  
Host是指主机名  
defaultCoreName是指默认使用的核心（不配置也完全可以）  
hostPort是指访问的端口（跟tomcat的端口保持一致）  
hostContext是指主机的上下文，也就是webapps中solr的项目名  

另外将core_activity/conf/下的schema.xml中`<schema name="core_activity" version="1.1">`及solrconfig.xml中的`<dataDir>${solr.core_activity.data.dir:}</dataDir>`等相关信息更新。  

重启tomcat，查看web管理界面左下是否出现新的索引库。  

# 配置中文分词器  

solr搜索时会将关键语句进行拆分，然后根据分割好的关键词进行相似搜索。而solr是默认没有提供中文分词的，在索引库下Analyse可以进行分词测试，我们输入中文测试时，不能够进行语句拆分。  

下面我们给我们的solr配置中文分词器(IK分词器)。  

1、下载 "IK Analyzer 2012FF_hf1.zip"包，详见[Ik Analyzer](http://zhengchao730.iteye.com/blog/1833000),[下载地址](https://code.google.com/archive/p/ik-analyzer/downloads)  

2、解压压缩包，将其中的`IKAnalyzer2012FF_u1.jar`拷贝到solr项目下的/WEB-INF/lib下，将`IKAnalyzer.cfg.xml`、`stopword.dic`拷贝到solr项目下的/WEB-INF/classes下。  

3、在每个核心中的schema.xml中配置IK分词器：  

```
<fieldType name="text_ik" class="solr.TextField">
     <analyzer type="index" isMaxWordLength="false" class="org.wltea.analyzer.lucene.IKAnalyzer"/>
     <analyzer type="query" isMaxWordLength="true" class="org.wltea.analyzer.lucene.IKAnalyzer"/>
</fieldType>
```  

这样就可以使用ik分词器了。  

其中`isMaxWordLength`是指分词的细粒度，可以分别制定index索引和query查询的分词细粒度，建议将index的`isMaxWordLength`设置为false，这样就采用最细分词，是索引更精确，查询时尽量能匹配，而将query的`isMaxWordLength`设置为true，采用最大分词，这样能够使查询出来的结果更符合用户的需求。  

在fields中配置一个filed来测试分词效果：  

```
<field name="title"        type="text_ik"    indexed="true"  stored="true"  multiValued="false" required="true"/>
```  

注：<field name="_version_" type="long"      indexed="true"  stored="true"/>不要去掉  

并将默认摸索字段修改为title，`<defaultSearchField>title</defaultSearchField>`。  

在索引库下Analyse中输入“中华人民共和国”测试分词效果。  

# 数据源配置  

1、在tomcat/conf/webapp-solr/localhost/solr.xml文件中的context下增加：  

```
<Resource name="jdbc/alltuu" auth="Container" type="javax.sql.DataSource" username="userName" password="userPwd" driverClassName="com.mysql.jdbc.Driver" url="jdbc:mysql://dbip:port/dbName" maxActive="-1"/>
```  

2、在每个核心中的solrconfig.xml中配置dataimport：  

```
<requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
    <lst name="defaults">
      <str name="config">dbconf/core_activity.xml</str>
    </lst>
</requestHandler>
```  

3、在每个核心的conf/下创建dbconf文件夹，并在文件夹下创建core_activity.xml:  

```
<?xml version="1.0" encoding="UTF-8" ?>
<dataConfig>
   <dataSource name="alltuu" jndiName="java:comp/env/jdbc/alltuu" type="JdbcDataSource"/>         
    <document>
       <entity name="activity" dataSource="alltuu" query="select id, title, adr_str from ps_activity">
          <field column="title" name="title" />
          <field column="adr_str" name="address" />
       </entity>
    </document>
 </dataConfig>
```  

dataSource：所使用的数据源，其中name为可选的，主要在使用多数据源时使用。  
Document：代表一个文档  
Entity：即需要从数据库中取出的数据，支持sql语句，支持多表查询。跨库查询后面会介绍  
Field：即接受到的数据，列名column和索引中的名称（必须和schema.xml）中field定义的名字一样。  

按照上面配置的数据源，在core_activity/schema.xml中完善filed信息。  

4、将`mysql-connector-java-5.1.9.jar`,`solr-dataimporthandler-4.4.0.jar`, `solr-dataimporthandler-extras-4.4.0.jar`复制到solr项目的WEB_INF/lib/下。  

在dataimport管理页面导入索引试试...  

# 定时重做索引与增量索引  

1、在solrhome下创建conf文件夹。  

2、将solr-dataimportscheduler-1.1.jar复制到solr项目的WEB_INF/lib/下，将dataimport.properties复制到上一步建立的conf文件夹中。  

3、修改solr项目WEB_INF/下面的web.xml文件，在在servlet节点前面增加:  

```
<listener>
    <listener-class>org.apache.solr.handler.dataimport.scheduler.ApplicationListener</listener-class>
</listener>
```  

4、按需要修改dataimport.properties文件，以达到符合预期的索引重建条件。  

现在可以重启tomcat观察日志，看其有没有定时重做索引。  

# 感谢  
